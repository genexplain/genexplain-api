{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The geneXplain platform Java API The geneXplain platform is a software that, as a web service, provides a comprehensive environment to analyze biomedical and biological data. Its functionality includes, among other things, data storage, management, sharing, running analysis tools from bioinformatics and systems biology, building and running analysis pipelines and workflows, building and visualizing molecuar network models, or developing quantitative models and simulation. This document describes the Java API for the geneXplain platform, which allows operation of platform functionality on a remote server using Java programs. Like user accounts for the platform, the API is freely available at GitHub . You clone its GitHub repository with the following shell command or download a ZIP archive from the repository website. 1 git clone https://github.com/genexplain/genexplain-api.git A JAR package of the software can be built using the Gradle build tool. 1 2 cd genexplain-api gradle build There are two main ways to make use of genexplain-api . On one hand, the software can be used as a library to build Java programs that interact with the geneXplain platform. On the other hand, the JAR created by the build script is executable and offers several applicatons as well as a JSON interface that enables configuration and execution of individual analysis jobs up to complex workflows. The core structure of the API is described in Java API . A number of examples in package com.genexplain.api.eg show how to apply it, whereas the section named JAR applications and JSON interface describes the different applications that can be executed from the JAR file as well as how to use the JSON interface including a Hello world -tutorial.","title":"Introduction"},{"location":"#the-genexplain-platform-java-api","text":"The geneXplain platform is a software that, as a web service, provides a comprehensive environment to analyze biomedical and biological data. Its functionality includes, among other things, data storage, management, sharing, running analysis tools from bioinformatics and systems biology, building and running analysis pipelines and workflows, building and visualizing molecuar network models, or developing quantitative models and simulation. This document describes the Java API for the geneXplain platform, which allows operation of platform functionality on a remote server using Java programs. Like user accounts for the platform, the API is freely available at GitHub . You clone its GitHub repository with the following shell command or download a ZIP archive from the repository website. 1 git clone https://github.com/genexplain/genexplain-api.git A JAR package of the software can be built using the Gradle build tool. 1 2 cd genexplain-api gradle build There are two main ways to make use of genexplain-api . On one hand, the software can be used as a library to build Java programs that interact with the geneXplain platform. On the other hand, the JAR created by the build script is executable and offers several applicatons as well as a JSON interface that enables configuration and execution of individual analysis jobs up to complex workflows. The core structure of the API is described in Java API . A number of examples in package com.genexplain.api.eg show how to apply it, whereas the section named JAR applications and JSON interface describes the different applications that can be executed from the JAR file as well as how to use the JSON interface including a Hello world -tutorial.","title":"The geneXplain platform Java API"},{"location":"java_api/","text":"Using the Java API The Java API has two main interfaces, com.genexplain.api.core.GxHttpConnection and com.genexplain.api.core.GxHttpClient and there are two basic implementations provided by com.genexplain.api.core.GxHttpConnectionImpl and com.genexplain.api.core.GxHttpClientImpl (see also Fig. 1). The GxHttpConnection manages a connection to a geneXplain platform server and provides low level methods to send requests to the server. The GxHttpClient requires a GxHttpConnection to be able to provide higher level functions, e.g., to submit analysis jobs, import or export data. The core functionality of the API is contained in the package com.genexplain.api.core . Figure 1. A) Two core interfaces providing a connection to a platform server and a client as well as their implementations. B) Overview of the roles of core classes in a program using the API. A program firstly creates a GxHttpConnection which is given authentication info and the address of the server to connect with (Fig. 1B). The connection object is then provided to the GxHttpClient to do its work. Several example programs in the package com.genexplain.api.eg demonstrate how to use the API. The described workflow of obtaining a connection and a client can be seen at work in the connect() method of the class com.genexplain.api.eg.AbstractAPIExample .","title":"Java API"},{"location":"java_api/#using-the-java-api","text":"The Java API has two main interfaces, com.genexplain.api.core.GxHttpConnection and com.genexplain.api.core.GxHttpClient and there are two basic implementations provided by com.genexplain.api.core.GxHttpConnectionImpl and com.genexplain.api.core.GxHttpClientImpl (see also Fig. 1). The GxHttpConnection manages a connection to a geneXplain platform server and provides low level methods to send requests to the server. The GxHttpClient requires a GxHttpConnection to be able to provide higher level functions, e.g., to submit analysis jobs, import or export data. The core functionality of the API is contained in the package com.genexplain.api.core . Figure 1. A) Two core interfaces providing a connection to a platform server and a client as well as their implementations. B) Overview of the roles of core classes in a program using the API. A program firstly creates a GxHttpConnection which is given authentication info and the address of the server to connect with (Fig. 1B). The connection object is then provided to the GxHttpClient to do its work. Several example programs in the package com.genexplain.api.eg demonstrate how to use the API. The described workflow of obtaining a connection and a client can be seen at work in the connect() method of the class com.genexplain.api.eg.AbstractAPIExample .","title":"Using the Java API"},{"location":"java_json_manual_intro/","text":"Using the Java JAR application The JAR file created by the genexplain-api build script is executable and offers a few applications described in the following sections. They can be executed by adding corresponding commands onto the commandline as first argument after the JAR path. To see which applications/commands are available just execute the JAR without arguments. Further arguments or parameters required by the applications can be seen by invoking the JAR with just their command name or the command name followed by -h . Often parameters are specified in a JSON file as second argument after the command . Here one can see four applications named regulator-search, exec, apps, example . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar Usage: java -jar ( ... ) .jar command args ... Available commands: regulator-search - JSON and Java interface to carry out a regulator search exec - Executes tasks configured in provided JSON file apps - Lists available analysis applications example - Runs examples Java packages to be scanned for ApplicationCommand implementations can be specified as system property using the java -D option For more info about each command try ( java -jar ... ) COMMAND -h --------------------------- Briefly, the program apps connects to a platform server using a specified account and retrieves a list of available analysis tools. The example application offers execution of a few selectable examples. The regulator-search can be used to run regulator and effector inferences on molecular networks. Through the exec command one can interact with a platform instance to down- or upload data, or to run analysis processes.","title":"Introduction"},{"location":"java_json_manual_intro/#using-the-java-jar-application","text":"The JAR file created by the genexplain-api build script is executable and offers a few applications described in the following sections. They can be executed by adding corresponding commands onto the commandline as first argument after the JAR path. To see which applications/commands are available just execute the JAR without arguments. Further arguments or parameters required by the applications can be seen by invoking the JAR with just their command name or the command name followed by -h . Often parameters are specified in a JSON file as second argument after the command . Here one can see four applications named regulator-search, exec, apps, example . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar Usage: java -jar ( ... ) .jar command args ... Available commands: regulator-search - JSON and Java interface to carry out a regulator search exec - Executes tasks configured in provided JSON file apps - Lists available analysis applications example - Runs examples Java packages to be scanned for ApplicationCommand implementations can be specified as system property using the java -D option For more info about each command try ( java -jar ... ) COMMAND -h --------------------------- Briefly, the program apps connects to a platform server using a specified account and retrieves a list of available analysis tools. The example application offers execution of a few selectable examples. The regulator-search can be used to run regulator and effector inferences on molecular networks. Through the exec command one can interact with a platform instance to down- or upload data, or to run analysis processes.","title":"Using the Java JAR application"},{"location":"json_hello_world/","text":"JSON interface tutorial The following sections show how to run platform tasks through the JSON interface and how to use its possibilities to build analysis workflows and pipelines. To execute the JSON configurations of the tutorial change to the subdirectory of the genexplain-api Git repository named docs/tutorial . Let us start with the Hello world example. Hello world example The output of the hello_world.json file contained in mentioned folder is shown below. The single task specified for the tasks property leads to execution of docs/tutorial/script.sh which simply echos the commandline input. 1 2 3 4 5 6 7 8 9 { withoutConnect : true , tasks : { do : external , showOutput : true , bin : sh , params : [ script.sh , Hello world ] } } 1 2 3 gene@xplain:genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec hello_world.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Hello world Lists of tasks Building pipelines and workflows is easy. One step to get started with this is to be able to specify lists of tasks that are executed sequentially. For this you just let tasks be a JSON array. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 { withoutConnect : true , tasks : [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } ] } Execute the tutorial file task_list.json to see this at work. 1 2 3 4 5 gene@xplain:genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec task_list.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3 Loading tasks from file A pipeline with many tasks may be more convenient to manage in multiple files. It is possible to load tasks from a file. We can simply write the three tasks of our previous example into a separate file and load the task array in our main object. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } ] In our main object we specify the file using the fromFile property as shown below. explain more details in the documentation. 1 2 3 4 5 6 7 8 { withoutConnect : true , tasks : { fromFile : { file : loadable_task_list.json } } } Running that we get: 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_list.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3 Deep nesting and infinite looping So, now we can write bigger task lists into separate files which is already one step towards maintaining more complex workflows, but sometimes it gets even more complex than is conveniently handled with one file for all the tasks. And indeed the JSON executor is not limited to what we have shown so far, but allows for arbitrary levels of nesting. What goes on in the backend is a recursive method that calls itself with JSON arguments until it finds a task that is processed by the specified executor. Deep nesting Let us create an extra level of nesting for task 1 in our example by specifying a list of tasks 1a - 1c in a separate file. We call this file nested_task_1.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1a ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1b ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1c ] } ] Next, we adapt our loadable_task_list by replacing for task 1 again an instruction that will cause the new file to be loaded. We call this new file loadable_nested_task_list.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [ { fromFile : { file : nested_task_1.json } }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } ] Our main JSON object actually only requires a change of file name in the fromFile property and we also save under the name loading_nested_task.json . 1 2 3 4 5 6 7 8 { withoutConnect : true , tasks : { fromFile : { file : loadable_nested_task_list.json } } } Executing it, we see the expected output. 1 2 3 4 5 6 7 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_nested_task_list.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1a INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1b INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1c INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3 As the output confirms, tasks 1a - 1c were loaded from the file specified in the outer task list. We can add more and more levels to this which allows us to break down workflows and pipelines into conveniently small and reusable pieces of JSON configurations. And on top of that, there are more ways of loading executable tasks as well as specifying task parameters through placeholders that make the whole more even easier to use and more flexible. Infinite flow Since the core executor function continues to call itself until it encounters an executable task, it is possible to build an infinitely running analysis pipeline. A possible use case is a process that continues to check for new data and analyzes them as soon as they are available. Here we focus on showing a way to build a self-perpetuating pipeline. Another important component for the described use case is to follow alternative analysis branches selected by some condition which is shown in a later part of the tutorial. Looking at the previous section, one can obviously create a self-perpetuating process by specifying an array of tasks in a file which itself is loaded again in the end. Let us call such a task file infinite_loop.json and configure tasks as shown below. So, at the end a fromFile instructions causes the same file to be loaded again, starting over the pipeline. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Starting infinite loop period ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Middle of infinite loop period ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , End of infinite loop period ] }, { fromFile : { file : infinite_loop.json } } ] Our main config only requires a change of file name to load the infinite_loop.json and we rename it as loading_infinite_loop.json . 1 2 3 4 5 6 7 8 { withoutConnect : true , tasks : { fromFile : { file : infinite_loop.json } } } Execution of the loading_infinite_loop.json results in the expected output and requires forceful interruption. 1 2 3 4 5 6 7 8 9 10 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_infinite_loop.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Starting infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Middle of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: End of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Starting infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Middle of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: End of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Starting infinite loop period [ ... ] Loading from a task library Until now, we have worked with lists of task objects. When I have taken the time to nicely write down the JSON config for some analysis tool, I would like to reuse it at different places. In the simple list format we have covered so far, the tasks are unnamed items and therefore not so easily accessible. Let us extend the main JSON config by one property that instructs the Java application to load task definitions from files. This property is called loadTasks and its value is an array with a list of files. A file that can be loaded contains JSON objects with key/value-pairs consisting of task name and task definition. Here we create such a file named task_lib.json for the three example tasks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { task1 : { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1 ] }, task2 : { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, task3 : { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } } This file is similar to the array of tasks in loadable_task_list.json , only that the outer structure is an object and the tasks have names. Next we adapt the main JSON config to load this small library of tasks. 1 2 3 4 5 6 7 8 9 10 11 { withoutConnect : true , loadTasks : [ task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } Executing the main JSON config shows the expected output, where it is important to note that the tasks are nevertheless executed in the specified order: 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3 Since the loadTasks value is an array, one can specify many files to load task definitions from. Parameter placeholders To make task definitions more reusable one can insert placeholders for parameters which are replaced by the desired value specified in the main config. Let us modify the task_lib.json file and substitute the output strings with placeholders as shown below. While we often use capital strings delimited by $-symbols, any readable string can be used as placeholder. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { task1 : { do : external , showOutput : true , bin : sh , params : [ script.sh , $FIRST_MESSAGE$ ] }, task2 : { do : external , showOutput : true , bin : sh , params : [ script.sh , SECOND_MESSAGE ] }, task3 : { do : external , showOutput : true , bin : sh , params : [ script.sh , third message ] } } In the main config we need to add a replaceStrings property whose value is an array of arrays. We use arrays here, because we want to maintain the order specified placeholders. For our example we add one array for each placeholder that shall be recognized with the replacement as second element. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { withoutConnect : true , replaceStrings : [ [ $FIRST_MESSAGE$ , First task ], [ SECOND_MESSAGE , Second task ], [ third message , Third task ] ], loadTasks : [ placeholder_task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } In the output of our example workflow the placeholders are replaced by the specified strings. 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib_with_placeholders.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: First task INFO c.genexplain.api.core.GxJsonExecutor - External output: Second task INFO c.genexplain.api.core.GxJsonExecutor - External output: Third task Note that any JSON value can be applied for replacement. Cascaded replacement To build pipelines from reusable task definitions and smaller workflows, it is important to know that the replaceStrings value is intentionally an array in order to take advantage of the sequence of substitutions. What happens in the code is that the program iterates over the placeholder strings and substitutes all occurrences in a task definition with the current replacement. This means that one can replace a placeholder with another placeholder whose value is defined a later position in the replaceStrings array. Here is an example. We change placeholders in the main config as shown below and save the new main config as loading_task_lib_multiple_replacements.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { withoutConnect : true , replaceStrings : [ [ $FIRST_MESSAGE$ , SECOND_MESSAGE ], [ SECOND_MESSAGE , third message ], [ third message , FINALLY ], [ FINALLY , Finally, they are all equal. ] ], loadTasks : [ placeholder_task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } And the output shows the result indicated by the final replacement value. 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib_multiple_replacements.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. This property of the placeholder handling is important to be able to create reusable task definitions with general placeholders, which can be customized as needed using a cascade of replacements defined in the main config. Local parameter settings Being able to specify parameters as needed is certainly important. Therefore, there is an executor named setParameters that can alter the replaceStrings items. In the following example we show how to modify existing items. In addition, setParameters can add items in the beginning or at the end of the replaceStrings array as well as remove placeholders. The latter features are explained in the corresponding documentation section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { withoutConnect : true , replaceStrings : [ [ $FIRST_MESSAGE$ , SECOND_MESSAGE ], [ SECOND_MESSAGE , third message ], [ third message , FINALLY ], [ FINALLY , Finally, they are all equal. ] ], loadTasks : [ placeholder_task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 }, { do : setParameters , set : { $FIRST_MESSAGE$ : Not anymore! , SECOND_MESSAGE : What happened? , FINALLY : This can be changed again. } }, { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 }, { do : setParameters , set : { $FIRST_MESSAGE$ : SECOND_MESSAGE , SECOND_MESSAGE : FINALLY , FINALLY : All equal again. } }, { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } And the output of this is: 1 2 3 4 5 6 7 8 9 10 11 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib_local_replacements.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Not anymore! INFO c.genexplain.api.core.GxJsonExecutor - External output: What happened? INFO c.genexplain.api.core.GxJsonExecutor - External output: This can be changed again. INFO c.genexplain.api.core.GxJsonExecutor - External output: All equal again. INFO c.genexplain.api.core.GxJsonExecutor - External output: All equal again. INFO c.genexplain.api.core.GxJsonExecutor - External output: All equal again.","title":"JSON interface Hello world tutorial"},{"location":"json_hello_world/#json-interface-tutorial","text":"The following sections show how to run platform tasks through the JSON interface and how to use its possibilities to build analysis workflows and pipelines. To execute the JSON configurations of the tutorial change to the subdirectory of the genexplain-api Git repository named docs/tutorial . Let us start with the Hello world example.","title":"JSON interface tutorial"},{"location":"json_hello_world/#hello-world-example","text":"The output of the hello_world.json file contained in mentioned folder is shown below. The single task specified for the tasks property leads to execution of docs/tutorial/script.sh which simply echos the commandline input. 1 2 3 4 5 6 7 8 9 { withoutConnect : true , tasks : { do : external , showOutput : true , bin : sh , params : [ script.sh , Hello world ] } } 1 2 3 gene@xplain:genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec hello_world.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Hello world","title":"Hello world example"},{"location":"json_hello_world/#lists-of-tasks","text":"Building pipelines and workflows is easy. One step to get started with this is to be able to specify lists of tasks that are executed sequentially. For this you just let tasks be a JSON array. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 { withoutConnect : true , tasks : [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } ] } Execute the tutorial file task_list.json to see this at work. 1 2 3 4 5 gene@xplain:genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec task_list.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3","title":"Lists of tasks"},{"location":"json_hello_world/#loading-tasks-from-file","text":"A pipeline with many tasks may be more convenient to manage in multiple files. It is possible to load tasks from a file. We can simply write the three tasks of our previous example into a separate file and load the task array in our main object. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } ] In our main object we specify the file using the fromFile property as shown below. explain more details in the documentation. 1 2 3 4 5 6 7 8 { withoutConnect : true , tasks : { fromFile : { file : loadable_task_list.json } } } Running that we get: 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_list.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3","title":"Loading tasks from file"},{"location":"json_hello_world/#deep-nesting-and-infinite-looping","text":"So, now we can write bigger task lists into separate files which is already one step towards maintaining more complex workflows, but sometimes it gets even more complex than is conveniently handled with one file for all the tasks. And indeed the JSON executor is not limited to what we have shown so far, but allows for arbitrary levels of nesting. What goes on in the backend is a recursive method that calls itself with JSON arguments until it finds a task that is processed by the specified executor.","title":"Deep nesting and infinite looping"},{"location":"json_hello_world/#deep-nesting","text":"Let us create an extra level of nesting for task 1 in our example by specifying a list of tasks 1a - 1c in a separate file. We call this file nested_task_1.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1a ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1b ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1c ] } ] Next, we adapt our loadable_task_list by replacing for task 1 again an instruction that will cause the new file to be loaded. We call this new file loadable_nested_task_list.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [ { fromFile : { file : nested_task_1.json } }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } ] Our main JSON object actually only requires a change of file name in the fromFile property and we also save under the name loading_nested_task.json . 1 2 3 4 5 6 7 8 { withoutConnect : true , tasks : { fromFile : { file : loadable_nested_task_list.json } } } Executing it, we see the expected output. 1 2 3 4 5 6 7 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_nested_task_list.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1a INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1b INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1c INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3 As the output confirms, tasks 1a - 1c were loaded from the file specified in the outer task list. We can add more and more levels to this which allows us to break down workflows and pipelines into conveniently small and reusable pieces of JSON configurations. And on top of that, there are more ways of loading executable tasks as well as specifying task parameters through placeholders that make the whole more even easier to use and more flexible.","title":"Deep nesting"},{"location":"json_hello_world/#infinite-flow","text":"Since the core executor function continues to call itself until it encounters an executable task, it is possible to build an infinitely running analysis pipeline. A possible use case is a process that continues to check for new data and analyzes them as soon as they are available. Here we focus on showing a way to build a self-perpetuating pipeline. Another important component for the described use case is to follow alternative analysis branches selected by some condition which is shown in a later part of the tutorial. Looking at the previous section, one can obviously create a self-perpetuating process by specifying an array of tasks in a file which itself is loaded again in the end. Let us call such a task file infinite_loop.json and configure tasks as shown below. So, at the end a fromFile instructions causes the same file to be loaded again, starting over the pipeline. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [ { do : external , showOutput : true , bin : sh , params : [ script.sh , Starting infinite loop period ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , Middle of infinite loop period ] }, { do : external , showOutput : true , bin : sh , params : [ script.sh , End of infinite loop period ] }, { fromFile : { file : infinite_loop.json } } ] Our main config only requires a change of file name to load the infinite_loop.json and we rename it as loading_infinite_loop.json . 1 2 3 4 5 6 7 8 { withoutConnect : true , tasks : { fromFile : { file : infinite_loop.json } } } Execution of the loading_infinite_loop.json results in the expected output and requires forceful interruption. 1 2 3 4 5 6 7 8 9 10 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_infinite_loop.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Starting infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Middle of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: End of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Starting infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Middle of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: End of infinite loop period INFO c.genexplain.api.core.GxJsonExecutor - External output: Starting infinite loop period [ ... ]","title":"Infinite flow"},{"location":"json_hello_world/#loading-from-a-task-library","text":"Until now, we have worked with lists of task objects. When I have taken the time to nicely write down the JSON config for some analysis tool, I would like to reuse it at different places. In the simple list format we have covered so far, the tasks are unnamed items and therefore not so easily accessible. Let us extend the main JSON config by one property that instructs the Java application to load task definitions from files. This property is called loadTasks and its value is an array with a list of files. A file that can be loaded contains JSON objects with key/value-pairs consisting of task name and task definition. Here we create such a file named task_lib.json for the three example tasks. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { task1 : { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 1 ] }, task2 : { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 2 ] }, task3 : { do : external , showOutput : true , bin : sh , params : [ script.sh , Executing task 3 ] } } This file is similar to the array of tasks in loadable_task_list.json , only that the outer structure is an object and the tasks have names. Next we adapt the main JSON config to load this small library of tasks. 1 2 3 4 5 6 7 8 9 10 11 { withoutConnect : true , loadTasks : [ task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } Executing the main JSON config shows the expected output, where it is important to note that the tasks are nevertheless executed in the specified order: 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 1 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 2 INFO c.genexplain.api.core.GxJsonExecutor - External output: Executing task 3 Since the loadTasks value is an array, one can specify many files to load task definitions from.","title":"Loading from a task library"},{"location":"json_hello_world/#parameter-placeholders","text":"To make task definitions more reusable one can insert placeholders for parameters which are replaced by the desired value specified in the main config. Let us modify the task_lib.json file and substitute the output strings with placeholders as shown below. While we often use capital strings delimited by $-symbols, any readable string can be used as placeholder. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 { task1 : { do : external , showOutput : true , bin : sh , params : [ script.sh , $FIRST_MESSAGE$ ] }, task2 : { do : external , showOutput : true , bin : sh , params : [ script.sh , SECOND_MESSAGE ] }, task3 : { do : external , showOutput : true , bin : sh , params : [ script.sh , third message ] } } In the main config we need to add a replaceStrings property whose value is an array of arrays. We use arrays here, because we want to maintain the order specified placeholders. For our example we add one array for each placeholder that shall be recognized with the replacement as second element. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { withoutConnect : true , replaceStrings : [ [ $FIRST_MESSAGE$ , First task ], [ SECOND_MESSAGE , Second task ], [ third message , Third task ] ], loadTasks : [ placeholder_task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } In the output of our example workflow the placeholders are replaced by the specified strings. 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib_with_placeholders.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: First task INFO c.genexplain.api.core.GxJsonExecutor - External output: Second task INFO c.genexplain.api.core.GxJsonExecutor - External output: Third task Note that any JSON value can be applied for replacement.","title":"Parameter placeholders"},{"location":"json_hello_world/#cascaded-replacement","text":"To build pipelines from reusable task definitions and smaller workflows, it is important to know that the replaceStrings value is intentionally an array in order to take advantage of the sequence of substitutions. What happens in the code is that the program iterates over the placeholder strings and substitutes all occurrences in a task definition with the current replacement. This means that one can replace a placeholder with another placeholder whose value is defined a later position in the replaceStrings array. Here is an example. We change placeholders in the main config as shown below and save the new main config as loading_task_lib_multiple_replacements.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { withoutConnect : true , replaceStrings : [ [ $FIRST_MESSAGE$ , SECOND_MESSAGE ], [ SECOND_MESSAGE , third message ], [ third message , FINALLY ], [ FINALLY , Finally, they are all equal. ] ], loadTasks : [ placeholder_task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } And the output shows the result indicated by the final replacement value. 1 2 3 4 5 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib_multiple_replacements.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. This property of the placeholder handling is important to be able to create reusable task definitions with general placeholders, which can be customized as needed using a cascade of replacements defined in the main config.","title":"Cascaded replacement"},{"location":"json_hello_world/#local-parameter-settings","text":"Being able to specify parameters as needed is certainly important. Therefore, there is an executor named setParameters that can alter the replaceStrings items. In the following example we show how to modify existing items. In addition, setParameters can add items in the beginning or at the end of the replaceStrings array as well as remove placeholders. The latter features are explained in the corresponding documentation section. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { withoutConnect : true , replaceStrings : [ [ $FIRST_MESSAGE$ , SECOND_MESSAGE ], [ SECOND_MESSAGE , third message ], [ third message , FINALLY ], [ FINALLY , Finally, they are all equal. ] ], loadTasks : [ placeholder_task_lib.json ], tasks : [ { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 }, { do : setParameters , set : { $FIRST_MESSAGE$ : Not anymore! , SECOND_MESSAGE : What happened? , FINALLY : This can be changed again. } }, { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 }, { do : setParameters , set : { $FIRST_MESSAGE$ : SECOND_MESSAGE , SECOND_MESSAGE : FINALLY , FINALLY : All equal again. } }, { fromLib : task1 }, { fromLib : task2 }, { fromLib : task3 } ] } And the output of this is: 1 2 3 4 5 6 7 8 9 10 11 genexplain-api/docs/tutorial$ java -jar ../../build/libs/genexplain-api-1.0.jar exec loading_task_lib_local_replacements.json INFO com.genexplain.api.app.APIRunner - Running command exec INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Finally, they are all equal. INFO c.genexplain.api.core.GxJsonExecutor - External output: Not anymore! INFO c.genexplain.api.core.GxJsonExecutor - External output: What happened? INFO c.genexplain.api.core.GxJsonExecutor - External output: This can be changed again. INFO c.genexplain.api.core.GxJsonExecutor - External output: All equal again. INFO c.genexplain.api.core.GxJsonExecutor - External output: All equal again. INFO c.genexplain.api.core.GxJsonExecutor - External output: All equal again.","title":"Local parameter settings"},{"location":"json_interface/","text":"JAR application manuals example - Example applications using the Java API Several examples show how to use the Java API. They can be listed by invoking the JAR with the example command. All of the example sources can be found in the package com.genexplain.api.eg . 1 2 3 4 5 6 7 8 9 10 11 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar example INFO com.genexplain.api.app.APIRunner - Running command example INFO com.genexplain.api.eg.ExampleRunner - createFolder - Creates a folder within the demo workspace and prints out the server response ( com.genexplain.api.eg.CreateFolderExample ) INFO com.genexplain.api.eg.ExampleRunner - extractGeneClasses - Extracts gene classes from a functional classification result applying criteria for filtering ( com.genexplain.api.eg.ExtractFunctionalClassGenesExample ) INFO com.genexplain.api.eg.ExampleRunner - getParameters - Fetches parameter descriptions for a specified analysis tool ( com.genexplain.api.eg.GetParametersExample ) INFO com.genexplain.api.eg.ExampleRunner - getTable - Gets a JSON response representing a data table and prints it to standard output ( com.genexplain.api.eg.GetTableExample ) INFO com.genexplain.api.eg.ExampleRunner - importTable - Imports a table to the specified path ( com.genexplain.api.eg.ImportTableExample ) INFO com.genexplain.api.eg.ExampleRunner - listAFolder - Gets a JSON response representing the contents of the data/Projects folder ( com.genexplain.api.eg.ListAFolderExample ) INFO com.genexplain.api.eg.ExampleRunner - putTable - Stores a table under the specified path ( com.genexplain.api.eg.PutTableExample ) INFO com.genexplain.api.eg.ExampleRunner - tfbsAnalysisForFolder - Analyzes binding site enrichment for all gene sets in a folder ( com.genexplain.api.eg.TfbsAnalysisForFolderExample ) INFO com.genexplain.api.eg.ExampleRunner - zipImport - Imports multiple files of same type as a ZIP archive ( com.genexplain.api.eg.ZipImportExample ) Each listed item represents an example that can be invoked by adding its name to the commandline, e.g. listAFolder : 1 2 3 4 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar example listAFolder INFO com.genexplain.api.app.APIRunner - Running command example INFO c.g.api.core.GxHttpConnectionImpl - Trying to log in INFO c.g.api.eg.ListAFolderExample - { names : [{ hasChildren :true, permissions :3, name : CRC_6_CpG_biomarkers , protection :2, class :0 } , { hasChildren :true, permissions :7, name : Demo project , protection :2, class :0 } , { hasChildren :true, permissions :3, name : MTX resistance , protection :2, class :0 }] , size :3, classes : [ biouml.model.Module ] , from :0, to :3, enabled :true } The example applications extractGeneClasses , tfbsAnalysisForFolder and zipImport require a configuration file in JSON format as additional commandline argument. Please refer to their class source codes ( com.genexplain.api.eg.ExtractFunctionalClassGenesExample , com.genexplain.api.eg.TfbsAnalysisForFolderExample , com.genexplain.api.eg.ZipImportExample ) for descriptions of the configurable parameters. Runnable example JSON files are provided in the docs/tutorial folder of the source repository. They are also shown below. Please note that some parts have been abbreviated. The extractGeneClasses demo extracts gene sets from the functional classification result specified by funClassTable firstly to a local folder named fun_class_gene_sets (specified by geneSetFolder ) and imports them to an output folder ( outputFolder ) in data/Projects/Demo project/Data ( geneSetPath ) using the default result folder name ( fun_class_gene_sets ). 1 2 3 4 5 6 7 8 9 10 11 { funClassTable : data/Examples/TNF-stimulation of HUVECs GSE2... , localTableFile : funclass_table.txt , minGroupSize : 50 , maxGroupSize : 1500 , minHits : 30 , maxHits : 150 , maxAdjustedPval : 1e-10 , geneSetFolder : fun_class_gene_sets , geneSetPath : data/Projects/Demo project/Data } The tfbsAnalysisForFolder demo conducts a search for enriched transcription factor binding sites for all gene sets of a folder ( inputFolder ). Gene sets of interest can be recognized by a regular expression ( inputRegex ), which defaults to .+ if omitted from the configuration. The gene set for comparison ( noSet ) is a table with Ensembl gene ids which shouldn't overlap with the gene sets of interest. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { inputFolder : data/Examples/TNF-stimulation of HUVECs GSE2... , inputRegex : .+response.+ , outputFolder : data/Projects/Demo project/Data/TFBS analysis for folder , noSet : data/Examples/TNF-stimulation of HUVECs GSE2... , profile : databases/TRANSFAC(R) (public)/Data/profiles/vertebrate_human_p0.001 , doSample : true , sampleNum : 5 , sampleSize : 1000 , from : -1000 , to : 100 , siteFeCutoff : 1.1 , siteFdrCutoff : 1e-4 , seqFeCutoff : 1.0 , seqFdrCutoff : 0.05 } The demo application zipImport imports a ZIP archive containing multiple files of the same type into the platform workspace. Besides login credentials, the local path of the archive and the platform destination folder one needs to specify the parameters for the file type-specific importer. Importer parameters for two frequent use cases, gene tables and CEL files, are also given in the source code. Parameters of the JSON shown below may require adaptation. 1 2 3 4 5 6 7 8 9 10 11 12 13 { user : optional user name , password : optional password , server : optional server URL , zipArchive : local_example_archive.zip , outputFolder : destination folder in platform , importParams : [ { name : cleanupFolder , value : false }, { name : preserveExtension , value : false }, { name : preserveArchiveStructure , value : false }, { name : importFormat , value : Affymetrix CEL file (*.cel) } ] } apps - Listing available tools The application named apps produces a listing of the available analysis tools on a certain server. It takes a single argument that specifies a file containing a JSON object with several properties of which only the server property is required. An example input file can be found in the json folder of this repository. Invoking the application with this file lists platform tools available for the demo account on the platform.genexplain.com server as shown here: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar apps json/application_lister_demo.json INFO com.genexplain.api.app.APIRunner - Running command apps Data manipulation/Annotate diagram Data manipulation/Annotate table Data manipulation/Annotate track with genes Data manipulation/Composite module to proteins Data manipulation/Convert table Data manipulation/Convert table to track Data manipulation/Convert table via homology Data manipulation/Create folder Data manipulation/Create miRNA promoters Data manipulation/Create random track Data manipulation/Create tissue-specific promoter track Data manipulation/Create transcript region track Data manipulation/Filter one track by another Data manipulation/Filter table Data manipulation/Filter track by condition Data manipulation/Gene set to track [ ... ] The parameters that can be specified with the JSON input file are described in the following table. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username withParameters If true will also list the platform tool parameters connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient . regulator-search - Regulator (and effector) search tool The regulator-search is a molecular network analysis tool that searches for important signaling molecules that may regulate the activity of input molecules. One can also search for common effectors of input molecules, which is called effector search. While this application is just named after the search for regulators, it offers both options. Here we introduce the overall concept, input data and parameters. Research articles describe the algorithm in more detail. The basis for this network analysis is formed by a database which describes the molecular network consisting of molecules and molecular complexes (nodes) and their interactions as well as biochemical reactions (edges). Such a network is illustrated in the following figure. A set of input molecules is located within the network (blue nodes), and many of them are connected via one or more (directed) interaction/reaction steps. In the regulator search, those nodes from which outgoing reaction cascades can reach one or more input molecules are potential regulators, whereas in the effector search the cascades start from the input molecules and are incoming from the point of a potential effector. The algorithm searches for target (effector or regulator) nodes within a specified maximal number of interaction/reaction steps. An illustration of such a search path connecting input molecules and an upstream regulator is shown in the following figure. To prioritize potential target nodes, the search routine calculates a score for each of them. The score takes into account several parameters such as the number of hits in the input set or the number of hits outside of the input set within the same search distance. Optionally, one can also specify weights for the input molecules as well as so-called decorations of the molecular network which can be used to associate weights with all network molecules, to add new interactions/reactions between molecules, or to omit nodes from the network as depicted in the following figure. . To obtain a normalized score, one can choose to run the algorithm for randomized input sets with other parameters fixed and to calculate a Z-score as well as a FDR. This application can either invoke the analysis on a specified platform server or just print out a corresponding JSON configuration. The printed JSON can be used with the exec command e.g. as part of a pipeline. Parameters Parameter Description searchEffectors Set true to do effector (downstream from inputs) instead of regulator (upstream from inputs) search server Server URL to connect to user Username to use for connection password Password that belongs to the username verbose Set true get more progress info reconnect Set true to allow attempts to reconnect in case the connection is interrupted connection-class Package and name of a Java class that extends com.genexplain.api.core.GxHttpConnection and will be used instead of the standard class client-class Package and name of a Java class that extends com.genexplain.api.core.GxHttpClient and will be used instead of the standard class replaceStrings Define string labels to be replaced by specified input parameters sourcePath Platform path of the input molecule set weightColumn Name of column in input table to assign weights to molecules (optional) isInputSizeLimited Set true to apply the input size limit inputSizeLimit Use only the first specified number of input molecules maxRadius Max. number of reaction steps that may connect input molecules and regulator/effector scoreCutoff Score cutoff to filter regulators bioHub Database with molecular network that are applied in the analysis species Species of input molecules calculatingFDR Set true to calculate FDR for regulators FDRcutoff FDR cutoff to filter regulators ZScoreCutoff Z-score cutoff to filter regulators penalty Penalty factor for false positives, that is molecules connected to a regulator within maxRadius steps that are not input molecules contextDecorators Augment network component with context values such as node weights tableName Parameter for contextDecorators : Platform path of a table with context nodes and weights tableColumn Parameter for contextDecorators : Column in corresponding table tableName that contains weights decayFactor Factor that specifies decay of context weights removeNodeDecorators Specify nodes to omit from the network. These are not considered in the analysis. inputTable Parameter for removeNodeDecorators : Platform path of a table with molecules to remove isoformFactor Set true to normalize weights of multi-forms outputTable Platform path for the result table justPrint Set true to just print the parameters that would be sent to the platform wait Set true to wait for analysis to complete instead of starting the job asynchronously progress Set true to obtain progress information Example JSON config for the Java application This is a runnable JSON example for the demo account that can be provided to the regulator-search command within an input file, e.g. by calling something like java -jar genexplain-api.jar regulator-search example.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 { searchEffectors : false , user : , password : , server : https://platform.genexplain.com , verbose : true , reconnect : true , sourcePath : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Normalized (RMA) DEGs with limma/Condition_1 vs. Condition_2/Up-regulated genes Ensembl_Enriched_motifs/Enriched motifs Summary filtered TFs Genes Entrez , weightColumn : Avg. adj. site FE , isInputSizeLimited : false , inputSizeLimit : 100000 , maxRadius : 3 , scoreCutoff : 0.1 , bioHub : GeneWays hub , species : Human (Homo sapiens) , calculatingFDR : true , FDRcutoff : 0.01 , ZScoreCutoff : 1.1 , penalty : 0.5 , isoformFactor : true , outputTable : data/Projects/Demo project/example_regulator_search , contextDecorators : [ { tableName : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Treatment vs. Control Genes Entrez , tableColumn : logFC , decayFactor : 0.01 } ], wait : true , progress : true , justPrint : true } Example JSON output of the Regulator/Effector search application This is example JSON output that is generated for the above example configuration. This output can be used with the JSON executor using the exec command. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 { server : https://platform.genexplain.com , password : , reconnect : true , user : , tasks : [{ wait : true , method : Regulator search , workflow : false , progress : true , do : analyze , parameters : [ { name : sourcePath , value : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Normalized (RMA) DEGs with limma/Condition_1 vs. Condition_2/Enriched motifs Summary filtered TFs Genes Entrez }, { name : weightColumn , value : Avg. adj. site FE }, { name : isInputSizeLimited , value : false }, { name : inputSizeLimit , value : 100000 }, { name : maxRadius , value : 3 }, { name : scoreCutoff , value : 0.1 }, { name : bioHub , value : GeneWays hub }, { name : species , value : Human (Homo sapiens) }, { name : calculatingFDR , value : true }, { name : FDRcutoff , value : 0.01 }, { name : ZScoreCutoff , value : 1.1 }, { name : penalty , value : 0.5 }, { name : decorators , value : [[ { name : decoratorName , value : Apply Context }, { name : parameters , value : [ { name : tableName , value : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Treatment vs. Control Genes Entrez }, { name : tableColumn , value : logFC }, { name : decayFactor , value : 0.01 } ] } ]] }, { name : isoformFactor , value : true }, { name : outputTable , value : data/Projects/Demo project/example_regulator_search } ] }], verbose : true } exec - Executing tasks using the JSON interface The exec application provides a rich interface to interact with platform servers using JSON documents to configure tasks. It is possible to create complex workflows including re-usable templates, loops and conditional branch points. The Hello world-tutorial demonstrates several ways of how to make use of this interface. A JSON document is an object in which the property do specifies an executor. An executor is a function provided by the interface, e.g. to import or export data. Parameters of the executor are also specified as properties of the JSON object. Main executors The following table describes available executors. Most of them correspond to public methods of the Java API , but some are only provided by the JSON interface, e.g. branch or external . Each executor and its JSON configuration is described in more detail in the following sections. Their usage is also demonstrated by several examples. Name Description analyze Calls the analysis method with specified parameters branch Executes a branch point createFolder Creates a folder export Export data using a dedicated exporter external Runs an external tool get Gets specified table imPort Import a data file using a dedicated importer itemParameters Lists parameters for specified application, importer, or exporter jobStatus Gets the status for a job id listItems Lists available application, importer, or exporter items list Lists contents of specified folder put Puts table into specified folder setParameters Sets/adds/removes parameter strings analyze The analyze executor runs an analysis tool or workflow on the remote server. method - Name of the platform tool or workflow, where orkflows are specified by their platform path. parameters - A JSON object with parameters of the analysis tool or workflow. workflow - Set true if the called method is a workflow. wait - Set true to wait for the analysis to finish. progress - Set true to obtain more progress information. 1 2 3 4 5 6 7 8 { do : analyze , method : name of tool or path to workflow , parameters : { }, workflow : false , wait : false , progress : false } branch Selects the next task or task set using a branch selector. branchSelector - The canonical name of the Java class that implements the executor. The JSON document can contain further properties that configure the selector. In addition, the JSON configuration that was used to invoke the exec application is handed to the selector. Please see example selector implementations in this source repository. 1 2 3 4 5 { do : branch , branchSelector : com.branch.selector.Class , other parameters : further properties used by the selector } createFolder path - Path of the parent folder. name - Name of the new folder. 1 2 3 4 5 { do : createFolder , path : platform path , name : name of new folder } export Exports an item from the platform workspace to a local file. file - Local file to create for the export. path - Path of the platform item to export. exporter - Name of the exporter to apply, e.g. Tab-separated text (*.txt) for a text table. parameters - Parameters to be specified to the exporter. 1 2 3 4 5 6 7 { do : export , file : local file path to store export , path : platform path to export , exporter : name of exporter , parameters : JsonObject with exporter parameters } external This executor invokes an external program, e.g. a C++ application or an R script. bin - The command to be executed. params - List of parameters to be specified to the external program. showOutput - Set true to get output of the external program printed to standard output. 1 2 3 4 5 6 { do : external , bin : command to execute , params : simple string or array of parameters to add to commandline , showOutput : set true to observe standard output of invoked tool } get Downloads a table from the platform workspace and optionally stores it in a local file and/or prints it to standard output. table - Platform path of the table to download. toFile - Path of file to which to write table. toStdout - Set true to get table printed on standard output. 1 2 3 4 5 6 { do : get , table : platform path of table to download , toFile : path of local file , toStdout : to print table object to standard output } imPort Imports a local file to the platform workspace. file - Local file to import. path - Platform path including the name of imported item. importer - The importer to apply, e.g. Tabular (*.txt, *.xls, *.tab, etc.) for tables. parameters - Parameters for the importer. 1 2 3 4 5 6 7 { do : imPort , file : local file to import , path : the designated import location in the platform , importer : name of importer , parameters : JsonObject with importer parameters } itemParameters This is a collectiv function that can get information about the available parameters for an analysis tool (application), exporter or importer. If the item is an exporter or importer, one needs to specify the corresponding target platform path to export or import. name - Item name which may be the name of an analysis tool, an exporter or an importer name. type - Type of item, one of application, exporter or importer. path - If the item is an exporter or importer, the corresponding platform path is required to determine possible context-dependent parameters. 1 2 3 4 5 6 { do : itemParameters , name : name of item for which to get parameters , type : type of item for which to get parameters: application, exporter, importer , path : if exporter or importer, path for which to get parameters in context with ex-/importer } jobStatus Returns the status of a running analysis job. jobId - Id of the job whose status is requested. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { do : jobStatus , jobId : id of platform job to request status , toFile : path of local file , toStdout : to print output to standard output } listItems Gets listings of available applications, importers or exporters. type - Type of items to list, one of application, exporter or importer. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { do : listItems , type : type of items to list: applications, importers, or exporters toFile : path of local file , toStdout : to print output to standard output } list Gets the listing of specified folder. folder - Platform folder to get listing for. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { do : list , folder : platform folder to get listing for toFile : path of local file , toStdout : to print output to standard output } put Uploads a table from specified local file into the platform workspace. file - Local file with data table to upload. skip - Number of lines to skip in the beginning of the file. delimiter - Column delimiter string. table - JSON array of arrays with data columns. Note that the table has no title row, but columns are specified separately. columns - Column definition by an array of two-element arrays giving column name and type, where type is one of Integer, Float, Boolean, or Text . path - Platform path to put table which includes the name of the table item in the platform workspace. 1 2 3 4 5 6 7 8 9 { do : put , file : file with data table to put into platform , skip : number of lines to skip in the beginning of input file , delimiter : delimiter of table columns in input file , table : array of arrays with data to put into platform , columns : array of two-element arrays specifying column names and type. The latter can be Integer, Float, Boolean, Text , path : destination path of table in platform } setParameters Sets/adds/removes string replacements in the parameter object that will modify parameters of subsequent tasks. set - a JSON object whose keys can be found in the replaceStrings array of the parameter object and whose value will replace the current one. remove - a JSON object whose keys will be removed from the replaceStrings array of the parameter object. before - an array of two-element arrays that are inserted in the beginning of the replaceStrings array. after - an array of two-element arrays that are appended to the replaceStrings array. 1 2 3 4 5 6 7 { do : setParameters , set : sets existing parameter to specified value , remove : removes existing parameter , before : add parameter before others in the parameter array , after : add parameter at the end of the parameter array }","title":"JAR application manuals"},{"location":"json_interface/#jar-application-manuals","text":"","title":"JAR application manuals"},{"location":"json_interface/#example-example-applications-using-the-java-api","text":"Several examples show how to use the Java API. They can be listed by invoking the JAR with the example command. All of the example sources can be found in the package com.genexplain.api.eg . 1 2 3 4 5 6 7 8 9 10 11 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar example INFO com.genexplain.api.app.APIRunner - Running command example INFO com.genexplain.api.eg.ExampleRunner - createFolder - Creates a folder within the demo workspace and prints out the server response ( com.genexplain.api.eg.CreateFolderExample ) INFO com.genexplain.api.eg.ExampleRunner - extractGeneClasses - Extracts gene classes from a functional classification result applying criteria for filtering ( com.genexplain.api.eg.ExtractFunctionalClassGenesExample ) INFO com.genexplain.api.eg.ExampleRunner - getParameters - Fetches parameter descriptions for a specified analysis tool ( com.genexplain.api.eg.GetParametersExample ) INFO com.genexplain.api.eg.ExampleRunner - getTable - Gets a JSON response representing a data table and prints it to standard output ( com.genexplain.api.eg.GetTableExample ) INFO com.genexplain.api.eg.ExampleRunner - importTable - Imports a table to the specified path ( com.genexplain.api.eg.ImportTableExample ) INFO com.genexplain.api.eg.ExampleRunner - listAFolder - Gets a JSON response representing the contents of the data/Projects folder ( com.genexplain.api.eg.ListAFolderExample ) INFO com.genexplain.api.eg.ExampleRunner - putTable - Stores a table under the specified path ( com.genexplain.api.eg.PutTableExample ) INFO com.genexplain.api.eg.ExampleRunner - tfbsAnalysisForFolder - Analyzes binding site enrichment for all gene sets in a folder ( com.genexplain.api.eg.TfbsAnalysisForFolderExample ) INFO com.genexplain.api.eg.ExampleRunner - zipImport - Imports multiple files of same type as a ZIP archive ( com.genexplain.api.eg.ZipImportExample ) Each listed item represents an example that can be invoked by adding its name to the commandline, e.g. listAFolder : 1 2 3 4 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar example listAFolder INFO com.genexplain.api.app.APIRunner - Running command example INFO c.g.api.core.GxHttpConnectionImpl - Trying to log in INFO c.g.api.eg.ListAFolderExample - { names : [{ hasChildren :true, permissions :3, name : CRC_6_CpG_biomarkers , protection :2, class :0 } , { hasChildren :true, permissions :7, name : Demo project , protection :2, class :0 } , { hasChildren :true, permissions :3, name : MTX resistance , protection :2, class :0 }] , size :3, classes : [ biouml.model.Module ] , from :0, to :3, enabled :true } The example applications extractGeneClasses , tfbsAnalysisForFolder and zipImport require a configuration file in JSON format as additional commandline argument. Please refer to their class source codes ( com.genexplain.api.eg.ExtractFunctionalClassGenesExample , com.genexplain.api.eg.TfbsAnalysisForFolderExample , com.genexplain.api.eg.ZipImportExample ) for descriptions of the configurable parameters. Runnable example JSON files are provided in the docs/tutorial folder of the source repository. They are also shown below. Please note that some parts have been abbreviated. The extractGeneClasses demo extracts gene sets from the functional classification result specified by funClassTable firstly to a local folder named fun_class_gene_sets (specified by geneSetFolder ) and imports them to an output folder ( outputFolder ) in data/Projects/Demo project/Data ( geneSetPath ) using the default result folder name ( fun_class_gene_sets ). 1 2 3 4 5 6 7 8 9 10 11 { funClassTable : data/Examples/TNF-stimulation of HUVECs GSE2... , localTableFile : funclass_table.txt , minGroupSize : 50 , maxGroupSize : 1500 , minHits : 30 , maxHits : 150 , maxAdjustedPval : 1e-10 , geneSetFolder : fun_class_gene_sets , geneSetPath : data/Projects/Demo project/Data } The tfbsAnalysisForFolder demo conducts a search for enriched transcription factor binding sites for all gene sets of a folder ( inputFolder ). Gene sets of interest can be recognized by a regular expression ( inputRegex ), which defaults to .+ if omitted from the configuration. The gene set for comparison ( noSet ) is a table with Ensembl gene ids which shouldn't overlap with the gene sets of interest. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 { inputFolder : data/Examples/TNF-stimulation of HUVECs GSE2... , inputRegex : .+response.+ , outputFolder : data/Projects/Demo project/Data/TFBS analysis for folder , noSet : data/Examples/TNF-stimulation of HUVECs GSE2... , profile : databases/TRANSFAC(R) (public)/Data/profiles/vertebrate_human_p0.001 , doSample : true , sampleNum : 5 , sampleSize : 1000 , from : -1000 , to : 100 , siteFeCutoff : 1.1 , siteFdrCutoff : 1e-4 , seqFeCutoff : 1.0 , seqFdrCutoff : 0.05 } The demo application zipImport imports a ZIP archive containing multiple files of the same type into the platform workspace. Besides login credentials, the local path of the archive and the platform destination folder one needs to specify the parameters for the file type-specific importer. Importer parameters for two frequent use cases, gene tables and CEL files, are also given in the source code. Parameters of the JSON shown below may require adaptation. 1 2 3 4 5 6 7 8 9 10 11 12 13 { user : optional user name , password : optional password , server : optional server URL , zipArchive : local_example_archive.zip , outputFolder : destination folder in platform , importParams : [ { name : cleanupFolder , value : false }, { name : preserveExtension , value : false }, { name : preserveArchiveStructure , value : false }, { name : importFormat , value : Affymetrix CEL file (*.cel) } ] }","title":"example - Example applications using the Java API"},{"location":"json_interface/#apps-listing-available-tools","text":"The application named apps produces a listing of the available analysis tools on a certain server. It takes a single argument that specifies a file containing a JSON object with several properties of which only the server property is required. An example input file can be found in the json folder of this repository. Invoking the application with this file lists platform tools available for the demo account on the platform.genexplain.com server as shown here: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar apps json/application_lister_demo.json INFO com.genexplain.api.app.APIRunner - Running command apps Data manipulation/Annotate diagram Data manipulation/Annotate table Data manipulation/Annotate track with genes Data manipulation/Composite module to proteins Data manipulation/Convert table Data manipulation/Convert table to track Data manipulation/Convert table via homology Data manipulation/Create folder Data manipulation/Create miRNA promoters Data manipulation/Create random track Data manipulation/Create tissue-specific promoter track Data manipulation/Create transcript region track Data manipulation/Filter one track by another Data manipulation/Filter table Data manipulation/Filter track by condition Data manipulation/Gene set to track [ ... ] The parameters that can be specified with the JSON input file are described in the following table. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username withParameters If true will also list the platform tool parameters connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient .","title":"apps - Listing available tools"},{"location":"json_interface/#regulator-search-regulator-and-effector-search-tool","text":"The regulator-search is a molecular network analysis tool that searches for important signaling molecules that may regulate the activity of input molecules. One can also search for common effectors of input molecules, which is called effector search. While this application is just named after the search for regulators, it offers both options. Here we introduce the overall concept, input data and parameters. Research articles describe the algorithm in more detail. The basis for this network analysis is formed by a database which describes the molecular network consisting of molecules and molecular complexes (nodes) and their interactions as well as biochemical reactions (edges). Such a network is illustrated in the following figure. A set of input molecules is located within the network (blue nodes), and many of them are connected via one or more (directed) interaction/reaction steps. In the regulator search, those nodes from which outgoing reaction cascades can reach one or more input molecules are potential regulators, whereas in the effector search the cascades start from the input molecules and are incoming from the point of a potential effector. The algorithm searches for target (effector or regulator) nodes within a specified maximal number of interaction/reaction steps. An illustration of such a search path connecting input molecules and an upstream regulator is shown in the following figure. To prioritize potential target nodes, the search routine calculates a score for each of them. The score takes into account several parameters such as the number of hits in the input set or the number of hits outside of the input set within the same search distance. Optionally, one can also specify weights for the input molecules as well as so-called decorations of the molecular network which can be used to associate weights with all network molecules, to add new interactions/reactions between molecules, or to omit nodes from the network as depicted in the following figure. . To obtain a normalized score, one can choose to run the algorithm for randomized input sets with other parameters fixed and to calculate a Z-score as well as a FDR. This application can either invoke the analysis on a specified platform server or just print out a corresponding JSON configuration. The printed JSON can be used with the exec command e.g. as part of a pipeline.","title":"regulator-search - Regulator (and effector) search tool"},{"location":"json_interface/#parameters","text":"Parameter Description searchEffectors Set true to do effector (downstream from inputs) instead of regulator (upstream from inputs) search server Server URL to connect to user Username to use for connection password Password that belongs to the username verbose Set true get more progress info reconnect Set true to allow attempts to reconnect in case the connection is interrupted connection-class Package and name of a Java class that extends com.genexplain.api.core.GxHttpConnection and will be used instead of the standard class client-class Package and name of a Java class that extends com.genexplain.api.core.GxHttpClient and will be used instead of the standard class replaceStrings Define string labels to be replaced by specified input parameters sourcePath Platform path of the input molecule set weightColumn Name of column in input table to assign weights to molecules (optional) isInputSizeLimited Set true to apply the input size limit inputSizeLimit Use only the first specified number of input molecules maxRadius Max. number of reaction steps that may connect input molecules and regulator/effector scoreCutoff Score cutoff to filter regulators bioHub Database with molecular network that are applied in the analysis species Species of input molecules calculatingFDR Set true to calculate FDR for regulators FDRcutoff FDR cutoff to filter regulators ZScoreCutoff Z-score cutoff to filter regulators penalty Penalty factor for false positives, that is molecules connected to a regulator within maxRadius steps that are not input molecules contextDecorators Augment network component with context values such as node weights tableName Parameter for contextDecorators : Platform path of a table with context nodes and weights tableColumn Parameter for contextDecorators : Column in corresponding table tableName that contains weights decayFactor Factor that specifies decay of context weights removeNodeDecorators Specify nodes to omit from the network. These are not considered in the analysis. inputTable Parameter for removeNodeDecorators : Platform path of a table with molecules to remove isoformFactor Set true to normalize weights of multi-forms outputTable Platform path for the result table justPrint Set true to just print the parameters that would be sent to the platform wait Set true to wait for analysis to complete instead of starting the job asynchronously progress Set true to obtain progress information","title":"Parameters"},{"location":"json_interface/#example-json-config-for-the-java-application","text":"This is a runnable JSON example for the demo account that can be provided to the regulator-search command within an input file, e.g. by calling something like java -jar genexplain-api.jar regulator-search example.json . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 { searchEffectors : false , user : , password : , server : https://platform.genexplain.com , verbose : true , reconnect : true , sourcePath : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Normalized (RMA) DEGs with limma/Condition_1 vs. Condition_2/Up-regulated genes Ensembl_Enriched_motifs/Enriched motifs Summary filtered TFs Genes Entrez , weightColumn : Avg. adj. site FE , isInputSizeLimited : false , inputSizeLimit : 100000 , maxRadius : 3 , scoreCutoff : 0.1 , bioHub : GeneWays hub , species : Human (Homo sapiens) , calculatingFDR : true , FDRcutoff : 0.01 , ZScoreCutoff : 1.1 , penalty : 0.5 , isoformFactor : true , outputTable : data/Projects/Demo project/example_regulator_search , contextDecorators : [ { tableName : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Treatment vs. Control Genes Entrez , tableColumn : logFC , decayFactor : 0.01 } ], wait : true , progress : true , justPrint : true }","title":"Example JSON config for the Java application"},{"location":"json_interface/#example-json-output-of-the-regulatoreffector-search-application","text":"This is example JSON output that is generated for the above example configuration. This output can be used with the JSON executor using the exec command. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 { server : https://platform.genexplain.com , password : , reconnect : true , user : , tasks : [{ wait : true , method : Regulator search , workflow : false , progress : true , do : analyze , parameters : [ { name : sourcePath , value : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Normalized (RMA) DEGs with limma/Condition_1 vs. Condition_2/Enriched motifs Summary filtered TFs Genes Entrez }, { name : weightColumn , value : Avg. adj. site FE }, { name : isInputSizeLimited , value : false }, { name : inputSizeLimit , value : 100000 }, { name : maxRadius , value : 3 }, { name : scoreCutoff , value : 0.1 }, { name : bioHub , value : GeneWays hub }, { name : species , value : Human (Homo sapiens) }, { name : calculatingFDR , value : true }, { name : FDRcutoff , value : 0.01 }, { name : ZScoreCutoff , value : 1.1 }, { name : penalty , value : 0.5 }, { name : decorators , value : [[ { name : decoratorName , value : Apply Context }, { name : parameters , value : [ { name : tableName , value : data/Examples/TNF-stimulation of HUVECs GSE2639, Affymetrix HG-U133A microarray/Data/DEGs with limma/Treatment vs. Control Genes Entrez }, { name : tableColumn , value : logFC }, { name : decayFactor , value : 0.01 } ] } ]] }, { name : isoformFactor , value : true }, { name : outputTable , value : data/Projects/Demo project/example_regulator_search } ] }], verbose : true }","title":"Example JSON output of the Regulator/Effector search application"},{"location":"json_interface/#exec-executing-tasks-using-the-json-interface","text":"The exec application provides a rich interface to interact with platform servers using JSON documents to configure tasks. It is possible to create complex workflows including re-usable templates, loops and conditional branch points. The Hello world-tutorial demonstrates several ways of how to make use of this interface. A JSON document is an object in which the property do specifies an executor. An executor is a function provided by the interface, e.g. to import or export data. Parameters of the executor are also specified as properties of the JSON object.","title":"exec - Executing tasks using the JSON interface"},{"location":"json_interface/#main-executors","text":"The following table describes available executors. Most of them correspond to public methods of the Java API , but some are only provided by the JSON interface, e.g. branch or external . Each executor and its JSON configuration is described in more detail in the following sections. Their usage is also demonstrated by several examples. Name Description analyze Calls the analysis method with specified parameters branch Executes a branch point createFolder Creates a folder export Export data using a dedicated exporter external Runs an external tool get Gets specified table imPort Import a data file using a dedicated importer itemParameters Lists parameters for specified application, importer, or exporter jobStatus Gets the status for a job id listItems Lists available application, importer, or exporter items list Lists contents of specified folder put Puts table into specified folder setParameters Sets/adds/removes parameter strings","title":"Main executors"},{"location":"json_interface/#analyze","text":"The analyze executor runs an analysis tool or workflow on the remote server. method - Name of the platform tool or workflow, where orkflows are specified by their platform path. parameters - A JSON object with parameters of the analysis tool or workflow. workflow - Set true if the called method is a workflow. wait - Set true to wait for the analysis to finish. progress - Set true to obtain more progress information. 1 2 3 4 5 6 7 8 { do : analyze , method : name of tool or path to workflow , parameters : { }, workflow : false , wait : false , progress : false }","title":"analyze"},{"location":"json_interface/#branch","text":"Selects the next task or task set using a branch selector. branchSelector - The canonical name of the Java class that implements the executor. The JSON document can contain further properties that configure the selector. In addition, the JSON configuration that was used to invoke the exec application is handed to the selector. Please see example selector implementations in this source repository. 1 2 3 4 5 { do : branch , branchSelector : com.branch.selector.Class , other parameters : further properties used by the selector }","title":"branch"},{"location":"json_interface/#createfolder","text":"path - Path of the parent folder. name - Name of the new folder. 1 2 3 4 5 { do : createFolder , path : platform path , name : name of new folder }","title":"createFolder"},{"location":"json_interface/#export","text":"Exports an item from the platform workspace to a local file. file - Local file to create for the export. path - Path of the platform item to export. exporter - Name of the exporter to apply, e.g. Tab-separated text (*.txt) for a text table. parameters - Parameters to be specified to the exporter. 1 2 3 4 5 6 7 { do : export , file : local file path to store export , path : platform path to export , exporter : name of exporter , parameters : JsonObject with exporter parameters }","title":"export"},{"location":"json_interface/#external","text":"This executor invokes an external program, e.g. a C++ application or an R script. bin - The command to be executed. params - List of parameters to be specified to the external program. showOutput - Set true to get output of the external program printed to standard output. 1 2 3 4 5 6 { do : external , bin : command to execute , params : simple string or array of parameters to add to commandline , showOutput : set true to observe standard output of invoked tool }","title":"external"},{"location":"json_interface/#get","text":"Downloads a table from the platform workspace and optionally stores it in a local file and/or prints it to standard output. table - Platform path of the table to download. toFile - Path of file to which to write table. toStdout - Set true to get table printed on standard output. 1 2 3 4 5 6 { do : get , table : platform path of table to download , toFile : path of local file , toStdout : to print table object to standard output }","title":"get"},{"location":"json_interface/#import","text":"Imports a local file to the platform workspace. file - Local file to import. path - Platform path including the name of imported item. importer - The importer to apply, e.g. Tabular (*.txt, *.xls, *.tab, etc.) for tables. parameters - Parameters for the importer. 1 2 3 4 5 6 7 { do : imPort , file : local file to import , path : the designated import location in the platform , importer : name of importer , parameters : JsonObject with importer parameters }","title":"imPort"},{"location":"json_interface/#itemparameters","text":"This is a collectiv function that can get information about the available parameters for an analysis tool (application), exporter or importer. If the item is an exporter or importer, one needs to specify the corresponding target platform path to export or import. name - Item name which may be the name of an analysis tool, an exporter or an importer name. type - Type of item, one of application, exporter or importer. path - If the item is an exporter or importer, the corresponding platform path is required to determine possible context-dependent parameters. 1 2 3 4 5 6 { do : itemParameters , name : name of item for which to get parameters , type : type of item for which to get parameters: application, exporter, importer , path : if exporter or importer, path for which to get parameters in context with ex-/importer }","title":"itemParameters"},{"location":"json_interface/#jobstatus","text":"Returns the status of a running analysis job. jobId - Id of the job whose status is requested. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { do : jobStatus , jobId : id of platform job to request status , toFile : path of local file , toStdout : to print output to standard output }","title":"jobStatus"},{"location":"json_interface/#listitems","text":"Gets listings of available applications, importers or exporters. type - Type of items to list, one of application, exporter or importer. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { do : listItems , type : type of items to list: applications, importers, or exporters toFile : path of local file , toStdout : to print output to standard output }","title":"listItems"},{"location":"json_interface/#list","text":"Gets the listing of specified folder. folder - Platform folder to get listing for. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { do : list , folder : platform folder to get listing for toFile : path of local file , toStdout : to print output to standard output }","title":"list"},{"location":"json_interface/#put","text":"Uploads a table from specified local file into the platform workspace. file - Local file with data table to upload. skip - Number of lines to skip in the beginning of the file. delimiter - Column delimiter string. table - JSON array of arrays with data columns. Note that the table has no title row, but columns are specified separately. columns - Column definition by an array of two-element arrays giving column name and type, where type is one of Integer, Float, Boolean, or Text . path - Platform path to put table which includes the name of the table item in the platform workspace. 1 2 3 4 5 6 7 8 9 { do : put , file : file with data table to put into platform , skip : number of lines to skip in the beginning of input file , delimiter : delimiter of table columns in input file , table : array of arrays with data to put into platform , columns : array of two-element arrays specifying column names and type. The latter can be Integer, Float, Boolean, Text , path : destination path of table in platform }","title":"put"},{"location":"json_interface/#setparameters","text":"Sets/adds/removes string replacements in the parameter object that will modify parameters of subsequent tasks. set - a JSON object whose keys can be found in the replaceStrings array of the parameter object and whose value will replace the current one. remove - a JSON object whose keys will be removed from the replaceStrings array of the parameter object. before - an array of two-element arrays that are inserted in the beginning of the replaceStrings array. after - an array of two-element arrays that are appended to the replaceStrings array. 1 2 3 4 5 6 7 { do : setParameters , set : sets existing parameter to specified value , remove : removes existing parameter , before : add parameter before others in the parameter array , after : add parameter at the end of the parameter array }","title":"setParameters"}]}